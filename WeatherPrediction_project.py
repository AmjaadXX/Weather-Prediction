# -*- coding: utf-8 -*-
"""deeplearning_project (6).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dQMgAY1qz-eJ0Lfr64DjZH10bdzmEdrC

# To open Google Drive in Colab
"""

from google.colab import drive

!nvidia-smi

drive.mount('/content/drive')

"""# import libraries"""

import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import keras
from tqdm import tqdm
from keras.callbacks import EarlyStopping,ModelCheckpoint
from sklearn.metrics import confusion_matrix , accuracy_score
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import glob
import pandas as pan
import matplotlib.pyplot as plotter
import warnings
warnings.filterwarnings('ignore')

from collections import Counter
from collections import defaultdict

!pip install tensorflow
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# Read images from the file"""

image_data='/content/drive/MyDrive/NotSplittedClasses'
pd.DataFrame(os.listdir(image_data),columns=['Files_Name'])

files = [i for i in glob.glob(image_data + "//*//*")]
np.random.shuffle(files)
labels = [os.path.dirname(i).split("/")[-1] for i in files]
data = zip(files, labels)
dataframe = pan.DataFrame(data, columns = ["Image", "Label"])
dataframe

"""# EDA"""

sns.countplot(x = dataframe["Label"])
plotter.xticks(rotation = 0);

unique_classes, counts = np.unique(labels, return_counts=True)
num_classes = len(unique_classes)

print(f"Number of unique classes: {num_classes}")

labels_type = "Nominal"

print("\nType of Labels (Y):", labels_type)

# Count occurrences of each class
class_counts = pd.Series(labels).value_counts()
class_counts

"""# Preprocessing"""

class_counts = Counter(labels)

le = LabelEncoder()
dataframe["Label"] = le.fit_transform(dataframe["Label"])

# Calculate statistics on encoded labels
unique_classes, counts = np.unique(dataframe["Label"], return_counts=True)

# **Mean:** Average value of labels (encoded numerical values)
mean_label = np.mean(dataframe["Label"])
print(f"Mean label (encoded): {mean_label}")

# **Mode:** Most frequent label
mode_label = Counter(dataframe["Label"]).most_common(1)[0][0]
print(f"Mode label (encoded): {mode_label}")

# **Standard deviation:** Spread of labels (encoded numerical values)
std_dev_label = np.std(dataframe["Label"])
print(f"Standard deviation of labels (encoded): {std_dev_label}")

"""# Split data"""

train_data_dir = image_data
batch_size = 64
target_size = (224, 224)
train_percentage = 0.7
test_percentage = 0.15
validation_percentage = 0.15

train_data = tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=test_percentage + validation_percentage,
    subset="training",
    seed=100,
    image_size=target_size,
    batch_size=batch_size,
)

remaining_data = tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=test_percentage + validation_percentage,
    subset="validation",
    seed=200,
    image_size=target_size,
    batch_size=batch_size,
)

validation_data = remaining_data.take(int(len(remaining_data) * (validation_percentage / (test_percentage + validation_percentage))))
test_data = remaining_data.skip(int(len(remaining_data) * (validation_percentage / (test_percentage + validation_percentage))))

print("Number of samples in training set:", len(train_data))
print("Number of samples in validation set:", len(validation_data))
print("Number of samples in test set:", len(test_data))

class_names=train_data.class_names
class_names

import matplotlib.pyplot as plt
import tensorflow as tf

# Assuming 'train_data' and 'class_names' are defined

plt.figure(figsize=(15, 20))

for images, labels in train_data.take(1):
    for i in range(12):
        ax = plt.subplot(12, 4, i + 1)

        # Convert the image to grayscale
        grayscale_image = tf.image.rgb_to_grayscale(images[i])
        grayscale_image = tf.squeeze(grayscale_image)

        plt.imshow(grayscale_image.numpy().astype("uint8"), cmap='gray')
        plt.title(class_names[labels[i]])
        plt.axis("off")

plt.show()

"""# Modeling"""

base_model = tf.keras.applications.EfficientNetV2M(input_shape=(224,224,3),include_top=False,weights='imagenet')
base_model.trainable = False
keras_model=keras.models.Sequential()
keras_model.add(base_model)
keras_model.add(keras.layers.Flatten())
keras_model.add(keras.layers.Dropout(0.5))
keras_model.add(keras.layers.Dense(6,activation=tf.nn.softmax))
keras_model.summary()

tf.keras.utils.plot_model(keras_model, to_file='model.png', show_shapes=True, show_layer_names=True,show_dtype=True,dpi=80)

checkpoint =ModelCheckpoint("my_keras_model.h5", save_best_only=True)

early_stopping =EarlyStopping(patience=5, restore_best_weights=True)

!nvidia-smi

keras_model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
hist=keras_model.fit(train_data, epochs=10, validation_data=validation_data, callbacks=[checkpoint,early_stopping])

"""# Model Performance"""

score, acc = keras_model.evaluate(test_data)
print('Test Loss =', score)
print('Test Accuracy =', acc)

score, acc = keras_model.evaluate(train_data)
print('Train Loss =', score)
print('Train Accuracy =', acc)

hist_=pd.DataFrame(hist.history)
hist_

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(hist_['loss'],label='Train_Loss')
plt.plot(hist_['val_loss'],label='Validation_Loss')
plt.title('Train_Loss & Validation_Loss',fontsize=20)
plt.legend()
plt.subplot(1,2,2)
plt.plot(hist_['accuracy'],label='Train_Accuracy')
plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')
plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)
plt.legend()

num_images = 6
image_batch, label_batch = next(iter(test_data))
image_batch = image_batch[:num_images]
label_batch = label_batch[:num_images]

predictions = keras_model.predict(image_batch)
predicted_labels = np.argmax(predictions, axis=1)

fig, axes = plt.subplots(2, 3, figsize=(12, 8))
axes = axes.flatten()
for i, (image, label, predicted_label) in enumerate(zip(image_batch, label_batch, predicted_labels)):
    axes[i].imshow(image.numpy().astype("uint8"))
    axes[i].set_title(f"True Label: {class_names[label]}\nPredicted Label: {class_names[predicted_label]}")
    axes[i].axis("off")

plt.tight_layout()
plt.show()